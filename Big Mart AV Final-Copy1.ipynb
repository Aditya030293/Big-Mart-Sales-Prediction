{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries:\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/Aditya/Desktop/BigMart/train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/Aditya/Desktop/BigMart/test.csv\")\n",
    "sub_df = pd.read_csv(\"C:/Users/Aditya/Desktop/BigMart/sample_submission.csv\",usecols=['Item_Identifier','Outlet_Identifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = 2020 - train['Outlet_Establishment_Year']\n",
    "test['Age'] = 2020 - test['Outlet_Establishment_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Item_Outlet_Sales'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(bins=50, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.hist(bins=50, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(np.log(train['Item_Visibility']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Visibility_log'] = np.log(train['Item_Visibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Identifier_Outlet_Identifier'] = train['Item_Identifier'].astype(str)+'_'+train['Outlet_Identifier']\n",
    "test['Item_Identifier_Outlet_Identifier'] = test['Item_Identifier'].astype(str)+'_'+test['Outlet_Identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-153f7e48720a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Item_Identifier_Outlet_Identifier'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Item_Identifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Outlet_Identifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['Item_Identifier_Outlet_Identifier'] = df['Item_Identifier'].astype(str)+'_'+df['Outlet_Identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Fat_Content'] = np.where(train['Item_Fat_Content'] == 'Low Fat',0,\n",
    "                            np.where(train['Item_Fat_Content'] == 'LF',0,\n",
    "                            np.where(train['Item_Fat_Content'] == 'low fat',0,1)))\n",
    "\n",
    "test['Item_Fat_Content'] = np.where(test['Item_Fat_Content'] == 'Low Fat',0,\n",
    "                           np.where(test['Item_Fat_Content'] == 'LF',0,\n",
    "                           np.where(test['Item_Fat_Content'] == 'low fat',0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Item_Fat_Content'] = np.where(df['Item_Fat_Content'] == 'Low Fat',0,\n",
    "                           np.where(df['Item_Fat_Content'] == 'LF',0,\n",
    "                           np.where(df['Item_Fat_Content'] == 'low fat',0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Item_Outlet_Sales'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7060.000000\n",
       "mean       12.857645\n",
       "std         4.643456\n",
       "min         4.555000\n",
       "25%         8.773750\n",
       "50%        12.600000\n",
       "75%        16.850000\n",
       "max        21.350000\n",
       "Name: Item_Weight, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Item_Weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4705.000000\n",
       "mean       12.695633\n",
       "std         4.664849\n",
       "min         4.555000\n",
       "25%         8.645000\n",
       "50%        12.500000\n",
       "75%        16.700000\n",
       "max        21.350000\n",
       "Name: Item_Weight, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Item_Weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Missing values:\n",
    "\n",
    "train['Item_Weight'] = train.groupby('Item_Identifier').transform(lambda x: x.fillna(x.mean()))\n",
    "test['Item_Weight'] = test.groupby('Item_Identifier').transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Item_Weight'] = df.groupby('Item_Identifier').transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Missing values:\n",
    "\n",
    "train['Item_Weight'] = train['Item_Weight'].fillna((train['Item_Weight'].mean()))\n",
    "test['Item_Weight'] = test['Item_Weight'].fillna((test['Item_Weight'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlet_Size'] = df['Outlet_Size'].fillna('Large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Type_MRP_total'] = train.groupby(['Item_Type'])['Item_MRP'].transform('sum')\n",
    "#train['Type_MRP_mean'] = train.groupby(['Item_Type'])['Item_MRP'].transform('mean')\n",
    "\n",
    "train['Out_Iden_MRP_total'] = train.groupby(['Outlet_Identifier'])['Item_MRP'].transform('sum')\n",
    "#train['Out_Iden_MRP_mean'] = train.groupby(['Outlet_Identifier'])['Item_MRP'].transform('mean')\n",
    "\n",
    "train['Year_MRP_total'] = train.groupby(['Outlet_Establishment_Year'])['Item_MRP'].transform('sum')\n",
    "#train['Year_MRP_mean'] = train.groupby(['Outlet_Establishment_Year'])['Item_MRP'].transform('mean')\n",
    "\n",
    "train['Out_Type_MRP_total'] = train.groupby(['Outlet_Type'])['Item_MRP'].transform('sum')\n",
    "#train['Out_Type_MRP_mean'] = train.groupby(['Outlet_Type'])['Item_MRP'].transform('mean')\n",
    "\n",
    "train['Item_Identifiere_MRP_total'] = train.groupby(['Item_Identifier'])['Item_MRP'].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Type_MRP_total'] = test.groupby(['Item_Type'])['Item_MRP'].transform('sum')\n",
    "#test['Type_MRP_mean'] = test.groupby(['Item_Type'])['Item_MRP'].transform('mean')\n",
    "\n",
    "test['Out_Iden_MRP_total'] = test.groupby(['Outlet_Identifier'])['Item_MRP'].transform('sum')\n",
    "#test['Out_Iden_MRP_mean'] = test.groupby(['Outlet_Identifier'])['Item_MRP'].transform('mean')\n",
    "\n",
    "test['Year_MRP_total'] = test.groupby(['Outlet_Establishment_Year'])['Item_MRP'].transform('sum')\n",
    "#test['Year_MRP_mean'] = test.groupby(['Outlet_Establishment_Year'])['Item_MRP'].transform('mean')\n",
    "\n",
    "test['Out_Type_MRP_total'] = test.groupby(['Outlet_Type'])['Item_MRP'].transform('sum')\n",
    "#test['Out_Type_MRP_mean'] = test.groupby(['Outlet_Type'])['Item_MRP'].transform('mean')\n",
    "\n",
    "\n",
    "test['Item_Identifiere_MRP_total'] = test.groupby(['Item_Identifier'])['Item_MRP'].transform('sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Identifier_Outlet_Identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>DRC49</td>\n",
       "      <td>8.670</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065120</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>145.7128</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>1985</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "      <td>4026.7584</td>\n",
       "      <td>DRC49_OUT027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>FDZ26</td>\n",
       "      <td>11.600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144241</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>239.4222</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3346.3108</td>\n",
       "      <td>FDZ26_OUT049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>DRG48</td>\n",
       "      <td>5.780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>145.2102</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>1997</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3062.0142</td>\n",
       "      <td>DRG48_OUT046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>DRK59</td>\n",
       "      <td>8.895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Hard Drinks</td>\n",
       "      <td>232.9616</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2812.3392</td>\n",
       "      <td>DRK59_OUT045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>FDH35</td>\n",
       "      <td>18.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100844</td>\n",
       "      <td>Starchy Foods</td>\n",
       "      <td>166.3526</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>164.4526</td>\n",
       "      <td>FDH35_OUT010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier  Item_Weight  Item_Fat_Content  Item_Visibility  \\\n",
       "4835           DRC49        8.670                 0         0.065120   \n",
       "5774           FDZ26       11.600                 1         0.144241   \n",
       "2169           DRG48        5.780                 0         0.014555   \n",
       "4217           DRK59        8.895                 0         0.000000   \n",
       "2159           FDH35       18.250                 0         0.100844   \n",
       "\n",
       "          Item_Type  Item_MRP Outlet_Identifier  Outlet_Establishment_Year  \\\n",
       "4835    Soft Drinks  145.7128            OUT027                       1985   \n",
       "5774          Dairy  239.4222            OUT049                       1999   \n",
       "2169    Soft Drinks  145.2102            OUT046                       1997   \n",
       "4217    Hard Drinks  232.9616            OUT045                       2002   \n",
       "2159  Starchy Foods  166.3526            OUT010                       1998   \n",
       "\n",
       "     Outlet_Size Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  \\\n",
       "4835      Medium               Tier 3  Supermarket Type3          4026.7584   \n",
       "5774      Medium               Tier 1  Supermarket Type1          3346.3108   \n",
       "2169       Small               Tier 1  Supermarket Type1          3062.0142   \n",
       "4217         NaN               Tier 2  Supermarket Type1          2812.3392   \n",
       "2159         NaN               Tier 3      Grocery Store           164.4526   \n",
       "\n",
       "     Item_Identifier_Outlet_Identifier  \n",
       "4835                      DRC49_OUT027  \n",
       "5774                      FDZ26_OUT049  \n",
       "2169                      DRG48_OUT046  \n",
       "4217                      DRK59_OUT045  \n",
       "2159                      FDH35_OUT010  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot Encoding:\n",
    "dummy = pd.get_dummies(train['Item_Type'])\n",
    "dummy1 = pd.get_dummies(test['Item_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(dummy,left_index = True, right_index = True)\n",
    "test = test.merge(dummy1,left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = train['Item_Type'].value_counts().to_dict()\n",
    "item_count1 = test['Item_Type'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Type'] = train['Item_Type'].map(item_count)\n",
    "test['Item_Type'] = test['Item_Type'].map(item_count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_count = train['Outlet_Identifier'].value_counts().to_dict()\n",
    "outlet_count1 = test['Outlet_Identifier'].value_counts().to_dict()\n",
    "\n",
    "\n",
    "train['Outlet_Identifier'] = train['Outlet_Identifier'].map(outlet_count)\n",
    "test['Outlet_Identifier'] = test['Outlet_Identifier'].map(outlet_count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = train['Item_Identifier'].value_counts().to_dict()\n",
    "item_count1 = test['Item_Identifier'].value_counts().to_dict()\n",
    "\n",
    "\n",
    "train['Item_Identifier'] = train['Item_Identifier'].map(item_count)\n",
    "test['Item_Identifier'] = test['Item_Identifier'].map(item_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot Encoding:\n",
    "dummy = pd.get_dummies(train['Outlet_Type'])\n",
    "dummy1 = pd.get_dummies(test['Outlet_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(dummy,left_index = True, right_index = True)\n",
    "test = test.merge(dummy1,left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot Encoding:\n",
    "dummy_loc = pd.get_dummies(train['Outlet_Location_Type'])\n",
    "dummy1_loc = pd.get_dummies(test['Outlet_Location_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(dummy_loc,left_index = True, right_index = True)\n",
    "test = test.merge(dummy1_loc,left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Outlet_Establishment_Year'] = train['Outlet_Establishment_Year'].map({\n",
    "        1985: 0,1987: 1,1997: 2,1998: 3,1999: 4,2002: 5,2004: 6,2007: 7,2009: 8 })\n",
    "\n",
    "\n",
    "test['Outlet_Establishment_Year'] = test['Outlet_Establishment_Year'].map({\n",
    "        1985: 0,1987: 1,1997: 2,1998: 3,1999: 4,2002: 5,2004: 6,2007: 7,2009: 8 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Missing Values:\n",
    "train['Outlet_Size'] = train['Outlet_Size'].fillna('Large')\n",
    "test['Outlet_Size'] = test['Outlet_Size'].fillna('Large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Outlet_Size'] = train['Outlet_Size'].map({'Large':0, 'Small':1,'Medium':2,'High':3})\n",
    "test['Outlet_Size'] = test['Outlet_Size'].map({'Large':0, 'Small':1,'Medium':2,'High':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(train.corr(),annot=True,fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything other feature\n",
    "\n",
    "def correlation(train, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = train.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = correlation(train, 0.75)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train['Item_Visibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(test['Item_Visibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outlires\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(X)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "new_df = X[filtered_entries]\n",
    "train_df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm = ['Item_Visibility']\n",
    "train['Item_Visibility_1'] = train[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Item_Visibility_1'] = test[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['Item_Visibility_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Outlet_Location_Type','Outlet_Type'], axis = 1, inplace = True)\n",
    "test.drop(['Outlet_Location_Type','Outlet_Type'], axis = 1, inplace = True)\n",
    "\n",
    "##,'Outlet_Size','Outlet_Identifier','Item_Identifier','Today','Item_Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['Item_Outlet_Sales']\n",
    "X = train.drop(['Item_Outlet_Sales','Item_Identifier_Outlet_Identifier','Outlet_Establishment_Year','Item_Fat_Content',\n",
    "               'Item_Identifier','Outlet_Identifier','Item_Visibility','Item_Weight'], axis=1)\n",
    "                \n",
    "####'Item_Visibility','Item_Weight'                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Item_Outlet_Sales'] = 0\n",
    "y_test = test[['Item_Outlet_Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.drop(['Item_Outlet_Sales','Item_Identifier_Outlet_Identifier','Outlet_Establishment_Year','Item_Fat_Content',\n",
    "                    'Item_Identifier','Outlet_Identifier','Item_Visibility','Item_Weight'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REgressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "#Evalution Metrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "xgb = xgboost.XGBRegressor(n_jobs=-1)\n",
    "et = ExtraTreesRegressor(n_jobs=-1)\n",
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "ds = DecisionTreeRegressor()\n",
    "cat = CatBoostRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "lgb = LGBMRegressor()\n",
    "lr = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = {\n",
    "\"LinearRegression\": LinearRegression(),\n",
    "\"KNeighborsRegressor\":KNeighborsRegressor(n_neighbors=2),\n",
    "\"AdaBoostRegressor\":AdaBoostRegressor(random_state=0, n_estimators=100),\n",
    "\"LGBMRegressor\":LGBMRegressor(),\n",
    "\"Ridge\": Ridge(alpha=1.0),\n",
    "\"ElasticNet\":ElasticNet(random_state=0),\n",
    "\"GradientBoostingRegressor\":GradientBoostingRegressor(random_state=0),\n",
    "\"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "\"ExtraTreesRegressor\": ExtraTreesRegressor(n_jobs=-1),\n",
    "\"RandomForestRegressor\": RandomForestRegressor(n_jobs=-1),\n",
    "\"XGBRegressor\":xgboost.XGBRegressor(n_jobs=-1),\n",
    "\"CatBoostRegressor\":CatBoostRegressor(iterations=900, depth=5, learning_rate=0.05,loss_function = 'RMSE')\n",
    "#\"VottingRegressor\": VotingRegressor([('rf', rf),('xgb',xgb),('et',et)],n_jobs=-1)\n",
    "#\"Stcking\" : StackingRegressor(estimators=[('et', et),('xgb',xgb),('rf',rf)], final_estimator=LinearRegression(), cv=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dic =  {\"Model\":[],\"R2_Train\":[],\"RMSE_Train\":[]}\n",
    "for name, model in reg.items():\n",
    "    if name == 'CatBoostRegressor':\n",
    "        model.fit(X, Y,verbose=False)\n",
    "        #model.fit(X_train_norm, Y,verbose=False)\n",
    "    else:\n",
    "        model.fit(X, Y)\n",
    "        #model.fit(X_train_norm, Y)\n",
    "    #y_test_pre = model.predict(test_df)\n",
    "    y_train_pre = model.predict(X)\n",
    "    #y_train_pre = model.predict(X_train_norm)\n",
    "    r2_train = r2_score(Y, y_train_pre)\n",
    "    rmse_train  = np.sqrt(mean_squared_error(Y, y_train_pre))\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"Model:\", name)\n",
    "    print(\"-----Training Data Evaluation-----\")\n",
    "    print(\"R2 Value: \", r2_score(Y, y_train_pre))\n",
    "    print(\"RMSE: \",np.sqrt(mean_squared_error(Y, y_train_pre)))\n",
    "    dic[\"Model\"].append(name)\n",
    "    dic[\"R2_Train\"].append(r2_train)\n",
    "    dic[\"RMSE_Train\"].append(rmse_train)\n",
    "#final_data = pd.DataFrame(dic)\n",
    "#print(\"==================================================================\")\n",
    "#print(\"Best Model\")\n",
    "#print(\"==================================================================\")\n",
    "#print(final_data.max())\n",
    "#print(\"==================================================================\")\n",
    "#final_data.sort_values(\"RMSE_Train\", axis = 0, ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(dic)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.sort_values(\"RMSE_Train\", axis = 0, ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = VotingRegressor([('rf',rf),('xgb',xgb),('knn',knn),('lgb',lgb),('cat',cat),('ds',ds)],n_jobs=-1)\n",
    "#model = StackingRegressor([('rf',rf),('xgb',xgb),('knn',knn),('lgb',lgb),('cat',cat),('ds',ds)],n_jobs=-1)\n",
    "\n",
    "###('rf',rf),('xgb',xgb),('lgb',lgb),('cat',cat)\n",
    "\n",
    "model.fit(X, Y)\n",
    "#model.fit(X_train_norm, Y)\n",
    "\n",
    "#y_test_pre = model.predict(test_df)\n",
    "#r2_train = r2_score(Y, y_train_pre)\n",
    "#rmse_train  = np.sqrt(mean_squared_error(Y, y_train_pre))\n",
    "#print(\"Model:\", name)\n",
    "#print(\"-----Training Data Evalution-----\")\n",
    "#print(\"R2 Value: \", r2_score(Y, y_train_pre))\n",
    "#print(\"RMSE: \",np.sqrt(mean_squared_error(Y, y_train_pre)))\n",
    "\n",
    "\n",
    "y_test_pre = model.predict(test_df)\n",
    "#y_test_pre = model.predict(X_test_norm)\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pre)\n",
    "rmse_test  = np.sqrt(mean_squared_error(y_test, y_test_pre))\n",
    "#print(\"Model:\", name)\n",
    "print(\"-----Training Data Evalution-----\")\n",
    "print(\"R2 Value: \", r2_score(y_test, y_test_pre))\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test, y_test_pre)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre_df = {'Item_Outlet_Sales': y_test_pre}\n",
    "test_pre_df = pd.DataFrame(test_pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = pd.concat([sub_df,test_pre_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dataset['Item_Outlet_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"C:/Users/Aditya/Desktop/BigMart/vot_xgb_rf_knn_cat3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
